{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9add1b",
   "metadata": {},
   "source": [
    "## Ensemble algoritmaları :\n",
    "\n",
    "Ensemble method için Bagging algoritmalardan Random forestı gördük. \n",
    "\n",
    "aynı veri seti üzerinde farklı modellerin eğitimini sağlar. Her model kendi tahminini yapar ve tahminlerin birleşiminden bir meta model oluşturulur. böylece en başarılı tahmini yapan güçlü bir model oluşturulur.\n",
    "İkiye ayrılır : bagging ve boosting olarak. \n",
    "\n",
    "#### Bagging ve boosting algoritm benzerlikleri : \n",
    "\n",
    "oylama üzerine çalışır, aynı türdeki modelleri birleştirir. yani sadece 1 model kullanırlar. Baggingde tüm modeller ayrı ayrı oluşur. her birisi ayrı ağaç oluşturuyor. onların oylarına istinaden bir karar alınır. Random forestta ise buna ek olarak featureslerin de oyları alınır. yani onların ağırlığına bakılır. \n",
    "\n",
    "#### Bagging ve boosting farkları : \n",
    "\n",
    "bagging te her bir data modele ayrı ayrı girer, yani her bir ağaça tüm data girer ve hepsinin skorları alınır en iyi skor alınan ağacın modeli kabul edilir. Boostingte her ağacın oyu eşit. bagging algoritmasının içine decision tree gömülü halde bulunur. \n",
    "\n",
    "Boostingte ise data ilk ağaca girer, sonrasında diğer ağaçlara yapraktan alınan sonuca göre girer, yani her yaprak birbirini etkiler. burda ise en iyi skor elde edenin oyu daha fazla olacaktır. \n",
    "\n",
    "bagging algoritmaları varyansı düşürmek için, boosting algoritmaları ise bias değerini düşürmek için hareket eder. sebebi ise bagging algoritmaları birbirlerinden habersiz çalışırlar yani tüm data her bir ağaca monte edilerek çalışır, boosting algoritmalarında ise her ağacın skoru diğer ağacı etkileyecektir. \n",
    "\n",
    "#### Bagging çalışma prensibi şu şekilde : örneğin bir muharlık seçimi var 100 kişi oy kullandı. hepsi birbirinin ne oy verdiğinde habersiz, ve oylama sonunda sandık sayılıyor, sonucunda 100 oydan en fazla oy alan muhtar oluyor. yani datayı her seferinde her ağaç datanın farklı yönlerine bakarak skorlar ve en yüksek skor alan seçilir.\n",
    "\n",
    "#### Boosting te ise : yine 100 kişi oy kullanıyor, ama bu sefer her oy kullanan birbirini etkiliyor, yani ilk oyu veren 2. oyu vereni, 2. oyu veren 3. oyu vereni etkiliyor.  yani ilk ağacın baktığı yere 2. ağaç bakmıyor o farklı bir yere bakıyor ve sonrasında tüm veriler toplanır, ortalama değer alınır.  er ağaç bilgisini diğer ağaca aktarır, bagginde ise aktarım olmaz.\n",
    "\n",
    "### Boosting :\n",
    "\n",
    "Tüm datasetini alır, modele atar, bu model bir prediction yapar, predictiona göre yeniden yapılan hatalara göre data noktalarını ağırlıklandırır, sonra sıradaki modele gider ama bir önceki datadan elde ettiği bilgileri aktararak prediction yapar, sırasıyla tüm data bitinceye kadar bu süreç devam eder. sonra sırasıyla her modelin oyunu alır, en yüksek olan oya göre predict yapar. yani kısacası bir data seçer sonra ondan elde ettikleri ile sırasıyla tüm modellere bilgileri aktararak devam eder. en sonda en yüksek ağırlık değeri alanı seçer. Boosting algoritmada her bir ağaca stump denir.\n",
    "\n",
    "2 tane algoritması vardır. AdaBoost ve Gradient Boosting tir. En önemli hyper parametreleri base_estimator ve n_estimator dur.\n",
    "\n",
    "#### AdaBoost :\n",
    "\n",
    "Datayı seçiyor ve onu en iyi böleceği yeri bulup ordan bölüyor. sonra tahminleme yapıyor. yapılan hatalı tahminne göre bir sonra ki ağacı farklı bir noktadan bölüyor. sonra o ağaçta yaptığı hatalı tahminlere göre yine diğer ağacı farklı yerden ayırıyor. her hata değeri sonucu bir ağırlık katsayısı hesaplanır. hata ne kadar az ise ağırlık değeri o kadar fazla olur. ve en fazla ağırlık değeri olan seçilir. log2 tabanına göre ağırlıkları hesaplanır. yalış tahmin edilen yerler ağırlıklandırılarak çalışır.\n",
    "\n",
    "##### a . base_estimator parameteresi : Default bırakırsak max_depth değeri 1 olan, bir decision tree oluşturur. eğer logistic regression verirsek ise logistic regresyon oluşturur.\n",
    "\n",
    "##### b. n_estimators : default değeri 50 dir. kaç tane oluşturacağımız ağaç adedi.\n",
    "\n",
    "#### Gradient Boosting :\n",
    "\n",
    "Bir önceki modelin yaptığı hataları iyileştirme üzerine çalışıyor. elimizde X futureler ve y targetımız var. ilk modele sokuyor. y - y_pred = residual değerlerini buluyor. sonra 2. modele geçerken artık futreler ile diğer residualleri tahmin etmeye çalışıyor. yani ilk model residual değerinden 2. model resudial değerlerini çıkarıyor. ve sırasıyla tüm model bitinceue kadar bu yöntem ile ilerliyor. learning_rate değeri sayısı kadar resudial değerlerini çıkarır. learning_rate = 0 olsun diyelim. resudial değeri 0 oluncaya kadar devam eder ama overfit durumu olabilir.\n",
    "\n",
    "#### XGBoost (Extreme Gradient Boosting) :\n",
    "\n",
    "En kullanışlı boosting algoritması. kendi içinde bir alfa değeri gibi regulazisyon değeri uygulayabiliriz. missing value de bile çalışabilir. ama missing valueden mutlaka kurtulmak gerekir. her bir ağaca geçerken kendi içinde cross validate yapar. aynı zamanda tüm işlemcileri kullanabilmekteyiz. Büyük datalarda hızlıdır. Eda ya gerek kalmadan missing valueleri ekarte eder. feature importance(futurelerden hangisi daha önemli onu veriyor.) Görselleştirme yapılamaz. açıklaması çok zor. hyper parametresi oldukça fazla.\n",
    "\n",
    "##### a . n_estimator parametresi default olarak 100 tane belirlenmiş.\n",
    "\n",
    "##### b. subsample parametresi default olarak 1 belirlenmiş. 1 demek tüm veriyi kullan demektir. bölmeden kullan demek.\n",
    "\n",
    "##### c. max_depth : default değeri 3 tür.\n",
    "\n",
    "##### d. learning_rate : default değeri 0.1 dir. n_estimator ile learning_rate dengelenmelidir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb607282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc1fd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily Time Spent on Site</th>\n",
       "      <th>Age</th>\n",
       "      <th>Area Income</th>\n",
       "      <th>Daily Internet Usage</th>\n",
       "      <th>Ad Topic Line</th>\n",
       "      <th>City</th>\n",
       "      <th>Male</th>\n",
       "      <th>Country</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Clicked on Ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.95</td>\n",
       "      <td>35</td>\n",
       "      <td>61833.90</td>\n",
       "      <td>256.09</td>\n",
       "      <td>Cloned 5thgeneration orchestration</td>\n",
       "      <td>Wrightburgh</td>\n",
       "      <td>0</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>2016-03-27 00:53:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.23</td>\n",
       "      <td>31</td>\n",
       "      <td>68441.85</td>\n",
       "      <td>193.77</td>\n",
       "      <td>Monitored national standardization</td>\n",
       "      <td>West Jodi</td>\n",
       "      <td>1</td>\n",
       "      <td>Nauru</td>\n",
       "      <td>2016-04-04 01:39:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.47</td>\n",
       "      <td>26</td>\n",
       "      <td>59785.94</td>\n",
       "      <td>236.50</td>\n",
       "      <td>Organic bottom-line service-desk</td>\n",
       "      <td>Davidton</td>\n",
       "      <td>0</td>\n",
       "      <td>San Marino</td>\n",
       "      <td>2016-03-13 20:35:42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.15</td>\n",
       "      <td>29</td>\n",
       "      <td>54806.18</td>\n",
       "      <td>245.89</td>\n",
       "      <td>Triple-buffered reciprocal time-frame</td>\n",
       "      <td>West Terrifurt</td>\n",
       "      <td>1</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2016-01-10 02:31:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.37</td>\n",
       "      <td>35</td>\n",
       "      <td>73889.99</td>\n",
       "      <td>225.58</td>\n",
       "      <td>Robust logistical utilization</td>\n",
       "      <td>South Manuel</td>\n",
       "      <td>0</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>2016-06-03 03:36:18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
       "0                     68.95   35     61833.90                256.09   \n",
       "1                     80.23   31     68441.85                193.77   \n",
       "2                     69.47   26     59785.94                236.50   \n",
       "3                     74.15   29     54806.18                245.89   \n",
       "4                     68.37   35     73889.99                225.58   \n",
       "\n",
       "                           Ad Topic Line            City  Male     Country  \\\n",
       "0     Cloned 5thgeneration orchestration     Wrightburgh     0     Tunisia   \n",
       "1     Monitored national standardization       West Jodi     1       Nauru   \n",
       "2       Organic bottom-line service-desk        Davidton     0  San Marino   \n",
       "3  Triple-buffered reciprocal time-frame  West Terrifurt     1       Italy   \n",
       "4          Robust logistical utilization    South Manuel     0     Iceland   \n",
       "\n",
       "             Timestamp  Clicked on Ad  \n",
       "0  2016-03-27 00:53:11              0  \n",
       "1  2016-04-04 01:39:02              0  \n",
       "2  2016-03-13 20:35:42              0  \n",
       "3  2016-01-10 02:31:19              0  \n",
       "4  2016-06-03 03:36:18              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('advertising2.csv')\n",
    "df.head()\n",
    "# internet sitesi tıklama durumları. sırasıyla tıklama durumlarını etkileyen futureler var."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f665d3e",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis and Visualization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58751732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Daily Time Spent on Site  1000 non-null   float64\n",
      " 1   Age                       1000 non-null   int64  \n",
      " 2   Area Income               1000 non-null   float64\n",
      " 3   Daily Internet Usage      1000 non-null   float64\n",
      " 4   Ad Topic Line             1000 non-null   object \n",
      " 5   City                      1000 non-null   object \n",
      " 6   Male                      1000 non-null   int64  \n",
      " 7   Country                   1000 non-null   object \n",
      " 8   Timestamp                 1000 non-null   object \n",
      " 9   Clicked on Ad             1000 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0180f7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily Time Spent on Site</th>\n",
       "      <th>Age</th>\n",
       "      <th>Area Income</th>\n",
       "      <th>Daily Internet Usage</th>\n",
       "      <th>Male</th>\n",
       "      <th>Clicked on Ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65.000200</td>\n",
       "      <td>36.009000</td>\n",
       "      <td>55000.000080</td>\n",
       "      <td>180.000100</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.853615</td>\n",
       "      <td>8.785562</td>\n",
       "      <td>13414.634022</td>\n",
       "      <td>43.902339</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.600000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>13996.500000</td>\n",
       "      <td>104.780000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.360000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>47031.802500</td>\n",
       "      <td>138.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.215000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>57012.300000</td>\n",
       "      <td>183.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.547500</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>65470.635000</td>\n",
       "      <td>218.792500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>91.430000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>79484.800000</td>\n",
       "      <td>269.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Daily Time Spent on Site          Age   Area Income  \\\n",
       "count               1000.000000  1000.000000   1000.000000   \n",
       "mean                  65.000200    36.009000  55000.000080   \n",
       "std                   15.853615     8.785562  13414.634022   \n",
       "min                   32.600000    19.000000  13996.500000   \n",
       "25%                   51.360000    29.000000  47031.802500   \n",
       "50%                   68.215000    35.000000  57012.300000   \n",
       "75%                   78.547500    42.000000  65470.635000   \n",
       "max                   91.430000    61.000000  79484.800000   \n",
       "\n",
       "       Daily Internet Usage         Male  Clicked on Ad  \n",
       "count           1000.000000  1000.000000     1000.00000  \n",
       "mean             180.000100     0.481000        0.50000  \n",
       "std               43.902339     0.499889        0.50025  \n",
       "min              104.780000     0.000000        0.00000  \n",
       "25%              138.830000     0.000000        0.00000  \n",
       "50%              183.130000     0.000000        0.50000  \n",
       "75%              218.792500     1.000000        1.00000  \n",
       "max              269.960000     1.000000        1.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5681e081",
   "metadata": {},
   "source": [
    "### Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe27910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['Daily Time Spent on Site', 'Age', 'Area Income','Daily Internet Usage', 'Male']]\n",
    "y = df['Clicked on Ad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372faca",
   "metadata": {},
   "source": [
    "### Modelling and Model Performance : \n",
    "\n",
    "Adaboost modelini kullanacağız. ensemble methodlardan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b7e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# target categoric olduğu için Classifier dedik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c041fb6",
   "metadata": {},
   "source": [
    "#### Default Model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "573ca509",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_pred = ada_model.predict(X_test)\n",
    "\n",
    "# randomforestta her ağaç birbirinden bağımsızdı, her ağacın verdiği oy birbirine eşitti. en son sayıyorduk. en fazla çıkan oy\n",
    "# hangi classa aitse o classı atıyorduk. \n",
    "\n",
    "# adaboostingte ise ağaçlar birbirini etkiler. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12fdb2",
   "metadata": {},
   "source": [
    "#### Metrics : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b71e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, accuracy_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix\n",
    "\n",
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Test_Set\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Train_Set\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67e22136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set\n",
      "[[41  3]\n",
      " [ 4 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        44\n",
      "           1       0.95      0.93      0.94        56\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "\n",
      "Train_Set\n",
      "[[454   2]\n",
      " [ 12 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       456\n",
      "           1       1.00      0.97      0.98       444\n",
      "\n",
      "    accuracy                           0.98       900\n",
      "   macro avg       0.98      0.98      0.98       900\n",
      "weighted avg       0.98      0.98      0.98       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(ada_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d88e573",
   "metadata": {},
   "source": [
    "### Cross Validate Control : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa812934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_accuracy     0.960000\n",
       "test_precision    0.968795\n",
       "test_recall       0.950505\n",
       "test_f1           0.958988\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(model, X_train, y_train, scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\"], cv = 10)\n",
    "df_scores = pd.DataFrame(scores, index = range(1, 11))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd22195",
   "metadata": {},
   "source": [
    "### AdaBossting Çalışma mantığı : \n",
    "\n",
    "örneğin elimizde bir data olsun ve 1000 tane değeri olsun. her ağaca 1000 tane değer aktarılır. fakat bu 1000 tane değer her ağaca aynı şekilde aktarılmaz. diyelim ilk ağaca 1000 tane gözlemi soktu. ve bu ağaçta doğru tahmin ettiği ve yanlış tahmin ettiği değerler çıktı. 2. ağaca tekrardan 1000 gözlem sokarken hatalı tahmin edilen gözlemleri ağırlıklandırarak sokar. yani hatalı tahmin edilen gözlemlerin sayılarını arttırıp tekrardan diğer ağaca aktarir. her ağaçta hata sayısı azalır. learnin_rate ise bir sonraki ağaca hatalı gözlemleri aktarırken hataları ne kadar ağırlıklandıracağını belirler. eğer learning_rate sayısının artması hatayı 0 ra indirecektir. ve bu sebeple overfiting tehlikesi artacaktır. bizim için ideal olan ağaç sayımızın fazla, learnin_rate sayımızn az olmasıdır. ağaç sayımız n_estimator, hata ağırlık oranımız lerning_rate dir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec40b2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09666667, 0.15660636, 0.29526371, 0.28593614, 0.35590938,\n",
       "       0.39210515, 0.36269642, 0.36981063, 0.38415067, 0.35773598,\n",
       "       0.3516825 , 0.37454891, 0.42018968, 0.42873964, 0.39973475,\n",
       "       0.43748548, 0.40219137, 0.45770547, 0.46274743, 0.40702713,\n",
       "       0.42891649, 0.43044307, 0.36904407, 0.42357491, 0.44299881,\n",
       "       0.38996104, 0.40345756, 0.41149436, 0.43690794, 0.42621951,\n",
       "       0.47745572, 0.47172434, 0.46458273, 0.42113437, 0.44541302,\n",
       "       0.4184376 , 0.42957773, 0.4504647 , 0.45939104, 0.42479237,\n",
       "       0.42440331, 0.42555073, 0.48041565, 0.46741902, 0.43362918,\n",
       "       0.427282  , 0.39972274, 0.41673326, 0.45575418, 0.44847986])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model.estimator_errors_\n",
    "\n",
    "# ile hata sayılarına göre ağırlık katsayıları belirler. burdaki katsayıların sayısı n_estimator sayısı kadardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7db64d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=3, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ağaç sayımız 3 tane olsun : \n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=3, random_state=42)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6cf5d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09666667, 0.15660636, 0.29526371])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimator_errors_\n",
    "# her ağacın errorlarını döndürür. değer 0 ra ne kadar yakınsa o kadar iyi tahmin yapmış demektir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30d953d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.117411476360216"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2*np.log((1-0.09666667)/0.09666667) # 1. ağaç için ağırlıklandırma katsayısı : class değeri 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7990c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8418492023096668"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2*np.log((1-0.15660636)/0.15660636) # 2. ağaç için ağırlıklandırma katsayısı : class değeri 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b385c099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43497739343711583"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2*np.log((1-0.29526371)/0.29526371) # 3. ağaç için ağırlıklandırma katsayısı : class değeri 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfd0f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 ağaç içinden 1 class değerine sahip ağacın ağırlıklandırma katsayısı 1.17, 0 class değerine sahip ağaçların ağırlıklandırma\n",
    "# katsayıları toplamı : 0.84 + 0.43 = 1.27 dir. 0 classına sahip ağaçların katsayıları 1 classına sahip ağaçtan daha büyük \n",
    "# olduğu için class değeri 0 olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8961a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator = np.array([20,30,50,100,200,250,300,350,400])\n",
    "learning_rate = np.linspace(0.01,5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b0951",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1d00bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostClassifier(random_state=42),\n",
       "             param_grid={'learning_rate': array([0.01      , 0.11183673, 0.21367347, 0.3155102 , 0.41734694,\n",
       "       0.51918367, 0.62102041, 0.72285714, 0.82469388, 0.92653061,\n",
       "       1.02836735, 1.13020408, 1.23204082, 1.33387755, 1.43571429,\n",
       "       1.53755102, 1.63938776, 1.74122449, 1.84306122, 1.94489796,\n",
       "       2.04673469, 2.14857143, 2.25040816, 2.352..., 2.45408163,\n",
       "       2.55591837, 2.6577551 , 2.75959184, 2.86142857, 2.96326531,\n",
       "       3.06510204, 3.16693878, 3.26877551, 3.37061224, 3.47244898,\n",
       "       3.57428571, 3.67612245, 3.77795918, 3.87979592, 3.98163265,\n",
       "       4.08346939, 4.18530612, 4.28714286, 4.38897959, 4.49081633,\n",
       "       4.59265306, 4.6944898 , 4.79632653, 4.89816327, 5.        ]),\n",
       "                         'n_estimators': array([ 20,  30,  50, 100, 200, 250, 300, 350, 400])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = AdaBoostClassifier(random_state= 42)\n",
    "\n",
    "param_grid = {\"n_estimators\": n_estimator, \"learning_rate\": learning_rate}\n",
    "\n",
    "ada_grid_model = GridSearchCV(model, param_grid, cv=5, scoring= 'f1')\n",
    "\n",
    "ada_grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "014015c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.11183673469387755, 'n_estimators': 100}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a0fda88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set\n",
      "[[40  4]\n",
      " [ 3 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.93      0.95      0.94        56\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "\n",
      "Train_Set\n",
      "[[453   3]\n",
      " [ 19 425]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       456\n",
      "           1       0.99      0.96      0.97       444\n",
      "\n",
      "    accuracy                           0.98       900\n",
      "   macro avg       0.98      0.98      0.98       900\n",
      "weighted avg       0.98      0.98      0.98       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(ada_grid_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24705f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set\n",
      "[[41  3]\n",
      " [ 4 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        44\n",
      "           1       0.95      0.93      0.94        56\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "\n",
      "Train_Set\n",
      "[[454   2]\n",
      " [ 12 432]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       456\n",
      "           1       1.00      0.97      0.98       444\n",
      "\n",
      "    accuracy                           0.98       900\n",
      "   macro avg       0.98      0.98      0.98       900\n",
      "weighted avg       0.98      0.98      0.98       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(ada_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aec96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf48032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
