{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d33dcc",
   "metadata": {},
   "source": [
    "## Ensemble Algoritmaları : \n",
    "\n",
    "Ensemble method için Bagging algoritmalardan Random forestı gördük.\n",
    "\n",
    "aynı veri seti üzerinde farklı modellerin eğitimini sağlar. Her model kendi tahminini yapar ve tahminlerin birleşiminden bir meta model oluşturulur. böylece en başarılı tahmini yapan güçlü bir model oluşturulur. İkiye ayrılır : bagging ve boosting olarak.\n",
    "\n",
    "#### Bagging ve boosting algoritm benzerlikleri :\n",
    "\n",
    "oylama üzerine çalışır, aynı türdeki modelleri birleştirir. yani sadece 1 model kullanırlar. Baggingde tüm modeller ayrı ayrı oluşur. her birisi ayrı ağaç oluşturuyor. onların oylarına istinaden bir karar alınır. Random forestta ise buna ek olarak featureslerin de oyları alınır. yani onların ağırlığına bakılır.\n",
    "\n",
    "#### Bagging ve boosting farkları :\n",
    "\n",
    "bagging te her bir data modele ayrı ayrı girer, yani her bir ağaça tüm data girer ve hepsinin skorları alınır en iyi skor alınan ağacın modeli kabul edilir. Boostingte her ağacın oyu eşit. bagging algoritmasının içine decision tree gömülü halde bulunur.\n",
    "\n",
    "Boostingte ise data ilk ağaca girer, sonrasında diğer ağaçlara yapraktan alınan sonuca göre girer, yani her yaprak birbirini etkiler. burda ise en iyi skor elde edenin oyu daha fazla olacaktır.\n",
    "\n",
    "bagging algoritmaları varyansı düşürmek için, boosting algoritmaları ise bias değerini düşürmek için hareket eder. sebebi ise bagging algoritmaları birbirlerinden habersiz çalışırlar yani tüm data her bir ağaca monte edilerek çalışır, boosting algoritmalarında ise her ağacın skoru diğer ağacı etkileyecektir.\n",
    "\n",
    "Bagging çalışma prensibi şu şekilde : örneğin bir muharlık seçimi var 100 kişi oy kullandı. hepsi birbirinin ne oy verdiğinde habersiz, ve oylama sonunda sandık sayılıyor, sonucunda 100 oydan en fazla oy alan muhtar oluyor. yani datayı her seferinde her ağaç datanın farklı yönlerine bakarak skorlar ve en yüksek skor alan seçilir.\n",
    "Boosting te ise : yine 100 kişi oy kullanıyor, ama bu sefer her oy kullanan birbirini etkiliyor, yani ilk oyu veren 2. oyu vereni, 2. oyu veren 3. oyu vereni etkiliyor. yani ilk ağacın baktığı yere 2. ağaç bakmıyor o farklı bir yere bakıyor ve sonrasında tüm veriler toplanır, ortalama değer alınır. er ağaç bilgisini diğer ağaca aktarır, bagginde ise aktarım olmaz.\n",
    "\n",
    "#### Boosting :\n",
    "\n",
    "Tüm datasetini alır, modele atar, bu model bir prediction yapar, predictiona göre yeniden yapılan hatalara göre data noktalarını ağırlıklandırır, sonra sıradaki modele gider ama bir önceki datadan elde ettiği bilgileri aktararak prediction yapar, sırasıyla tüm data bitinceye kadar bu süreç devam eder. sonra sırasıyla her modelin oyunu alır, en yüksek olan oya göre predict yapar. yani kısacası bir data seçer sonra ondan elde ettikleri ile sırasıyla tüm modellere bilgileri aktararak devam eder. en sonda en yüksek ağırlık değeri alanı seçer. Boosting algoritmada her bir ağaca stump denir.\n",
    "\n",
    "2 tane algoritması vardır. AdaBoost ve Gradient Boosting tir. En önemli hyper parametreleri base_estimator ve n_estimator dur.\n",
    "\n",
    "#### AdaBoost :\n",
    "\n",
    "Datayı seçiyor ve onu en iyi böleceği yeri bulup ordan bölüyor. sonra tahminleme yapıyor. yapılan hatalı tahminne göre bir sonra ki ağacı farklı bir noktadan bölüyor. sonra o ağaçta yaptığı hatalı tahminlere göre yine diğer ağacı farklı yerden ayırıyor. her hata değeri sonucu bir ağırlık katsayısı hesaplanır. hata ne kadar az ise ağırlık değeri o kadar fazla olur. ve en fazla ağırlık değeri olan seçilir. log2 tabanına göre ağırlıkları hesaplanır. yalış tahmin edilen yerler ağırlıklandırılarak çalışır.\n",
    "\n",
    "a . base_estimator parameteresi : Default bırakırsak max_depth değeri 1 olan, bir decision tree oluşturur. eğer logistic regression verirsek ise logistic regresyon oluşturur.\n",
    "\n",
    "b. n_estimators : default değeri 50 dir. kaç tane oluşturacağımız ağaç adedi.\n",
    "\n",
    "c. learning_rate : hataları çarpacağı katsayı oranı.\n",
    "\n",
    "#### Gradient Boosting :\n",
    "\n",
    "Bir önceki modelin yaptığı hataları iyileştirme üzerine çalışıyor. elimizde X futureler ve y targetımız var. ilk modele sokuyor. y - y_pred = residual değerlerini buluyor. sonra 2. modele geçerken artık futreler ile diğer residualleri tahmin etmeye çalışıyor. yani ilk model residual değerinden 2. model resudial değerlerini çıkarıyor. ve sırasıyla tüm model bitinceue kadar bu yöntem ile ilerliyor. learning_rate değeri sayısı kadar resudial değerlerini çıkarır. learning_rate = 0 olsun diyelim. resudial değeri 0 oluncaya kadar devam eder ama overfit durumu olabilir.\n",
    "\n",
    "#### XGBoost (Extreme Gradient Boosting) :\n",
    "\n",
    "En kullanışlı boosting algoritması. kendi içinde bir alfa değeri gibi regulazisyon değeri uygulayabiliriz. missing value de bile çalışabilir. ama missing valueden mutlaka kurtulmak gerekir. her bir ağaca geçerken kendi içinde cross validate yapar. aynı zamanda tüm işlemcileri kullanabilmekteyiz. Büyük datalarda hızlıdır. Eda ya gerek kalmadan missing valueleri ekarte eder. feature importance(futurelerden hangisi daha önemli onu veriyor.) Görselleştirme yapılamaz. açıklaması çok zor. hyper parametresi oldukça fazla.\n",
    "\n",
    "a . n_estimator parametresi default olarak 100 tane belirlenmiş. b. subsample parametresi default olarak 1 belirlenmiş. 1 demek tüm veriyi kullan demektir. bölmeden kullan demek. c. max_depth : default değeri 3 tür. d. learning_rate : default değeri 0.1 dir. n_estimator ile learning_rate dengelenmelidir.\n",
    "\n",
    "#### Gradient Boosting çalışma mantığı :\n",
    "\n",
    "Regression için :\n",
    "\n",
    "Adaboosttan farklı bir çalıma şekli vardır. burda gerçek değerden tahmin edilen değer çıkarılır. sonra o çıkan farklı 0 değerine yaklaştırmaya çalışmaktadır.\n",
    "\n",
    "#### Classification için :\n",
    "\n",
    "her gözlem için bir başlangıç olasılığı belirler. Örneğin elmizde 4 tane 1, 2 tanede 0 değeri olsun. log10(4/2) = 0.69 değerini bulur. sonra log10(0.69) = 0.67 değerini bulur. sonuç 0.67 çıktığı için o da 0.5 ten büyüktür, o zaman ilk gözlem class değerini 1 ile başlatacak demektir. sonra 1 class değeri için : 1 - 0.67 = 0.33 resudial değerini atar. 0 için ise = 0.33 - 1 = -0.67 değerini resudial değeri olarak atar. sonra bir sonra ki ağaçta gelecek olan class değerine göre resudial değerini 0 ra yaklaştırmaya çalışır. ilk başlangıç olasılığı + learnin_rate * resudial ... ile tüm resudial değerlerini her bir class değeri için ayrı arı yapar. 1 classı için bir toplam, 0 classı için bir toplam elde eder. ilk class için elde edilen toplam 0.5 ten büyükse 1, 2. class için elde edilen toplam değeri 0.5 ten büyükse 1, 0.5 ten küçükse 0 olarak atayacaktı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2df6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.warn(\"this will not show\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb7b826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily Time Spent on Site</th>\n",
       "      <th>Age</th>\n",
       "      <th>Area Income</th>\n",
       "      <th>Daily Internet Usage</th>\n",
       "      <th>Ad Topic Line</th>\n",
       "      <th>City</th>\n",
       "      <th>Male</th>\n",
       "      <th>Country</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Clicked on Ad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.95</td>\n",
       "      <td>35</td>\n",
       "      <td>61833.90</td>\n",
       "      <td>256.09</td>\n",
       "      <td>Cloned 5thgeneration orchestration</td>\n",
       "      <td>Wrightburgh</td>\n",
       "      <td>0</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>2016-03-27 00:53:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.23</td>\n",
       "      <td>31</td>\n",
       "      <td>68441.85</td>\n",
       "      <td>193.77</td>\n",
       "      <td>Monitored national standardization</td>\n",
       "      <td>West Jodi</td>\n",
       "      <td>1</td>\n",
       "      <td>Nauru</td>\n",
       "      <td>2016-04-04 01:39:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.47</td>\n",
       "      <td>26</td>\n",
       "      <td>59785.94</td>\n",
       "      <td>236.50</td>\n",
       "      <td>Organic bottom-line service-desk</td>\n",
       "      <td>Davidton</td>\n",
       "      <td>0</td>\n",
       "      <td>San Marino</td>\n",
       "      <td>2016-03-13 20:35:42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.15</td>\n",
       "      <td>29</td>\n",
       "      <td>54806.18</td>\n",
       "      <td>245.89</td>\n",
       "      <td>Triple-buffered reciprocal time-frame</td>\n",
       "      <td>West Terrifurt</td>\n",
       "      <td>1</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2016-01-10 02:31:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.37</td>\n",
       "      <td>35</td>\n",
       "      <td>73889.99</td>\n",
       "      <td>225.58</td>\n",
       "      <td>Robust logistical utilization</td>\n",
       "      <td>South Manuel</td>\n",
       "      <td>0</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>2016-06-03 03:36:18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Daily Time Spent on Site  Age  Area Income  Daily Internet Usage  \\\n",
       "0                     68.95   35     61833.90                256.09   \n",
       "1                     80.23   31     68441.85                193.77   \n",
       "2                     69.47   26     59785.94                236.50   \n",
       "3                     74.15   29     54806.18                245.89   \n",
       "4                     68.37   35     73889.99                225.58   \n",
       "\n",
       "                           Ad Topic Line            City  Male     Country  \\\n",
       "0     Cloned 5thgeneration orchestration     Wrightburgh     0     Tunisia   \n",
       "1     Monitored national standardization       West Jodi     1       Nauru   \n",
       "2       Organic bottom-line service-desk        Davidton     0  San Marino   \n",
       "3  Triple-buffered reciprocal time-frame  West Terrifurt     1       Italy   \n",
       "4          Robust logistical utilization    South Manuel     0     Iceland   \n",
       "\n",
       "             Timestamp  Clicked on Ad  \n",
       "0  2016-03-27 00:53:11              0  \n",
       "1  2016-04-04 01:39:02              0  \n",
       "2  2016-03-13 20:35:42              0  \n",
       "3  2016-01-10 02:31:19              0  \n",
       "4  2016-06-03 03:36:18              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('advertising2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3316e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Daily Time Spent on Site  1000 non-null   float64\n",
      " 1   Age                       1000 non-null   int64  \n",
      " 2   Area Income               1000 non-null   float64\n",
      " 3   Daily Internet Usage      1000 non-null   float64\n",
      " 4   Ad Topic Line             1000 non-null   object \n",
      " 5   City                      1000 non-null   object \n",
      " 6   Male                      1000 non-null   int64  \n",
      " 7   Country                   1000 non-null   object \n",
      " 8   Timestamp                 1000 non-null   object \n",
      " 9   Clicked on Ad             1000 non-null   int64  \n",
      "dtypes: float64(3), int64(3), object(4)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0340dd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Daily Time Spent on Site</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>65.00020</td>\n",
       "      <td>15.853615</td>\n",
       "      <td>32.60</td>\n",
       "      <td>51.3600</td>\n",
       "      <td>68.215</td>\n",
       "      <td>78.5475</td>\n",
       "      <td>91.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>36.00900</td>\n",
       "      <td>8.785562</td>\n",
       "      <td>19.00</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>61.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area Income</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>55000.00008</td>\n",
       "      <td>13414.634022</td>\n",
       "      <td>13996.50</td>\n",
       "      <td>47031.8025</td>\n",
       "      <td>57012.300</td>\n",
       "      <td>65470.6350</td>\n",
       "      <td>79484.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily Internet Usage</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>180.00010</td>\n",
       "      <td>43.902339</td>\n",
       "      <td>104.78</td>\n",
       "      <td>138.8300</td>\n",
       "      <td>183.130</td>\n",
       "      <td>218.7925</td>\n",
       "      <td>269.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.48100</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clicked on Ad</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count         mean           std       min  \\\n",
       "Daily Time Spent on Site  1000.0     65.00020     15.853615     32.60   \n",
       "Age                       1000.0     36.00900      8.785562     19.00   \n",
       "Area Income               1000.0  55000.00008  13414.634022  13996.50   \n",
       "Daily Internet Usage      1000.0    180.00010     43.902339    104.78   \n",
       "Male                      1000.0      0.48100      0.499889      0.00   \n",
       "Clicked on Ad             1000.0      0.50000      0.500250      0.00   \n",
       "\n",
       "                                 25%        50%         75%       max  \n",
       "Daily Time Spent on Site     51.3600     68.215     78.5475     91.43  \n",
       "Age                          29.0000     35.000     42.0000     61.00  \n",
       "Area Income               47031.8025  57012.300  65470.6350  79484.80  \n",
       "Daily Internet Usage        138.8300    183.130    218.7925    269.96  \n",
       "Male                          0.0000      0.000      1.0000      1.00  \n",
       "Clicked on Ad                 0.0000      0.500      1.0000      1.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e420e68",
   "metadata": {},
   "source": [
    "### Train | Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40077686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['Daily Time Spent on Site', 'Age', 'Area Income','Daily Internet Usage', 'Male']]\n",
    "y = df['Clicked on Ad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a125a",
   "metadata": {},
   "source": [
    "### Default Modelling : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f526b23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9e8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier # XCBClassifier kullanacağız. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581ed420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(random_state = 42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4c239",
   "metadata": {},
   "source": [
    "#### Parametreleri : \n",
    "\n",
    "max_depth : ağacın derinliği sayısı\n",
    "learnin_rate : resudial değerinin çarpıldığı katsayı\n",
    "n_estimator : ağaç sayısı\n",
    "booster : gbtree yani decision tree algoritması var.\n",
    "objective : binary:logistic arka planda logistic regression çalışıyor. hem tree hem linear algoritmasını birleştirmiş.\n",
    "\n",
    "reg_alpha : 0 ise lasso, 1 ise ridge algoritması çalışır.\n",
    "reg_lambda : 1 ise ridge dir, 0 ise lasso dur. \n",
    "\n",
    "min_child_weighed : 1 ise lassodur. ama istenirse 1 den daha büyük değerlerde verilebilir. değer arttıkça overfitin durumu azalır. \n",
    "\n",
    "gamma : overfiting için önemli bir parametredir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8390af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'enable_categorical': False,\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 4,\n",
       " 'num_parallel_tree': 1,\n",
       " 'predictor': 'auto',\n",
       " 'random_state': 42,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da2fd36",
   "metadata": {},
   "source": [
    "### Metrics : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f8231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Test_Set\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Train_Set\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb75bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set\n",
      "[[40  4]\n",
      " [ 3 53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.93      0.95      0.94        56\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.93      0.93      0.93       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n",
      "\n",
      "Train_Set\n",
      "[[456   0]\n",
      " [  0 444]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       456\n",
      "           1       1.00      1.00      1.00       444\n",
      "\n",
      "    accuracy                           1.00       900\n",
      "   macro avg       1.00      1.00      1.00       900\n",
      "weighted avg       1.00      1.00      1.00       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(xgb_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b78430",
   "metadata": {},
   "source": [
    "### Cross validate : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c09ff528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test_accuracy     0.956667\n",
       "test_precision    0.966827\n",
       "test_recall       0.945859\n",
       "test_f1           0.955630\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "\n",
    "scores = cross_validate(model, X_train, y_train, scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\"], cv = 10)\n",
    "df_scores = pd.DataFrame(scores, index = range(1, 11))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624525c",
   "metadata": {},
   "source": [
    "### Gridsearch :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c66ea3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:19:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"n_estimators\":[50, 100, 200],'max_depth':[3,4,5], \"learning_rate\": [0.1, 0.2],\n",
    "             \"subsample\":[0.5, 0.8, 1], \"colsample_bytree\":[0.5,0.7, 1]}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_model, param_grid, scoring = \"recall\",  n_jobs = -1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07b2b485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 50,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14261e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Set\n",
      "[[40  4]\n",
      " [ 2 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        44\n",
      "           1       0.93      0.96      0.95        56\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.94      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n",
      "\n",
      "Train_Set\n",
      "[[453   3]\n",
      " [ 15 429]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       456\n",
      "           1       0.99      0.97      0.98       444\n",
      "\n",
      "    accuracy                           0.98       900\n",
      "   macro avg       0.98      0.98      0.98       900\n",
      "weighted avg       0.98      0.98      0.98       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metric(xgb_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d9b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
